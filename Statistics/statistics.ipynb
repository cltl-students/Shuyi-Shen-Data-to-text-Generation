{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffab3c17-0384-4847-9428-e351cef85d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os \n",
    "import random\n",
    "import sklearn.utils as su\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba055fc-f917-4793-9921-38fddcdb97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../Classifier/PRGC-job/data/job/raw_data/merge_data_version6.json\"\n",
    "train_path = \"../Classifier/PRGC-job/data/job/train_triples.json\"\n",
    "dev_path = \"../Classifier/PRGC-job/data/job/val_triples.json\"\n",
    "test_path = \"../Classifier/PRGC-job/data/job/test_triples.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58dc3d2-b33a-44a0-8079-f3e578e000c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, \"r\",encoding = 'utf-8') as fr:\n",
    "        return [json.loads(line.strip()) for line in fr.readlines()]\n",
    "\n",
    "def split_to_tran_dev_test(source_path):\n",
    "    \"\"\"\n",
    "    split annotation files(after transforming) to train, val, test splits.\n",
    "    \"\"\"\n",
    "    # with open(source_path, \"r\", encoding = 'utf-8') as fr:\n",
    "    #     data = json.load(fr)\n",
    "    data = read_json(source_path)\n",
    "    shuffle_data = su.shuffle(data, random_state=7)   \n",
    "    data_size = len(data)\n",
    "    All_data = shuffle_data[: int(1*data_size)]\n",
    "    train_data = shuffle_data[: int(0.8*data_size)]\n",
    "    dev_data = shuffle_data[int(0.8*data_size) : int(0.9*data_size)]\n",
    "    test_data = shuffle_data[int(0.9*data_size):]\n",
    "    \n",
    "    return All_data,  train_data , dev_data, test_data \n",
    "\n",
    "def triple_list(source_path):\n",
    "    \"\"\"\n",
    "    split annotation files(after transforming) to train, val, test splits.\n",
    "    \"\"\"\n",
    "    Experience_skills, Knowledge_skills,  Experience_areas, Knowledge_areas, Degree_in = 0,0,0,0,0\n",
    "    with open(source_path, \"r\", encoding = 'utf-8') as fr:\n",
    "        data = json.load(fr)\n",
    "    for item in data:\n",
    "        triples = item[\"triple_list\"]\n",
    "        Experience_skills+= len([triple[1] for triple in triples if triple[1] == \"Experience_skills\" ])\n",
    "        Knowledge_skills+= len([triple[1] for triple in triples if triple[1] == \"knowledge_skills\" ])\n",
    "        Experience_areas += len([triple[1] for triple in triples if triple[1] == \"Experience_areas\" ])\n",
    "        Knowledge_areas+= len([triple[1] for triple in triples if triple[1] == \"knowledge_areas\" ])\n",
    "        Degree_in+= len([triple[1] for triple in triples if triple[1] == \"degree_in\" ])\n",
    "    \n",
    "    Relations =   [Experience_skills, Knowledge_skills, Experience_areas, \n",
    "                   Knowledge_areas, Degree_in]\n",
    "    return Relations\n",
    "        \n",
    "def transform_format(data):\n",
    "    \"\"\"\n",
    "    transform raw data to this code repository.\n",
    "    source path: raw data path\n",
    "    source path: transformed data path\n",
    "    \"\"\"\n",
    "    # data points in total\n",
    "    length_dataset = len(data)\n",
    "    # print('There are {} data points in {}'.format( length_dataset,path), '\\n')\n",
    "    Experience, Knowledge, Skills, Areas, Diploma, Major = 0,0,0,0,0,0\n",
    "    Experience_skills, Knowledge_skills,  Experience_areas, Knowledge_areas, Degree_in = 0,0,0,0,0\n",
    "    length_texts = 0\n",
    "    length_words = 0\n",
    "    length_triple_list = 0\n",
    "    for item in data:\n",
    "        tokens = item[\"spans\"]\n",
    "        words = item[\"tokens\"]\n",
    "        length_words  += len([word[\"text\"] for word in words])\n",
    "        # The number of sentences per data point\n",
    "        length_texts += len(item['text'].split('\\n'))\n",
    "        # calculate length of each entity per data point\n",
    "        Experience+= len([token[\"label\"] for token in tokens if token[\"label\"] == \"experience\" ])\n",
    "        Knowledge+= len([token[\"label\"] for token in tokens if token[\"label\"] == \"knowledge\" ])\n",
    "        Skills += len([token[\"label\"] for token in tokens if token[\"label\"] == \"skills\" ])\n",
    "        Areas+= len([token[\"label\"] for token in tokens if token[\"label\"] == \"areas\" ])\n",
    "        Diploma+= len([token[\"label\"] for token in tokens if token[\"label\"] == \"diploma\" ])\n",
    "        Major+= len([token[\"label\"] for token in tokens if token[\"label\"] == \"major\" ])\n",
    "        # calculate length of each relation per data point\n",
    "        relations = item[\"relations\"]\n",
    "       \n",
    "        Experience_skills+= len([relation[\"label\"] for relation in relations if relation[\"label\"] == \"Experience_skills\" ])\n",
    "        Knowledge_skills+= len([relation[\"label\"] for relation in relations if relation[\"label\"] == \"knowledge_skills\" ])\n",
    "        Experience_areas += len([relation[\"label\"] for relation in relations if relation[\"label\"] == \"Experience_areas\" ])\n",
    "        Knowledge_areas+= len([relation[\"label\"] for relation in relations if relation[\"label\"] == \"knowledge_areas\" ])\n",
    "        Degree_in+= len([relation[\"label\"] for relation in relations if relation[\"label\"] == \"degree_in\" ])\n",
    "        \n",
    "        triple_list = []\n",
    "        tokens = item[\"tokens\"]\n",
    "        tokens = [token[\"text\"] for token in tokens]\n",
    "        \n",
    "        for r in item[\"relations\"]:\n",
    "            head_text = \" \".join(\n",
    "                tokens[r[\"head_span\"][\"token_start\"]: r[\"head_span\"][\"token_end\"]+1]\n",
    "            )\n",
    "            child_text = \" \".join(\n",
    "                tokens[r[\"child_span\"][\"token_start\"]: r[\"child_span\"][\"token_end\"]+1]\n",
    "            )\n",
    "            triple_list.append(\n",
    "                [head_text, r[\"label\"], child_text]\n",
    "            )\n",
    "        length_triple_list +=len(triple_list)\n",
    "    \n",
    "    Average_length_word = round((length_words/ length_dataset), 2) \n",
    "    Average_length_sent = round((length_texts/ length_dataset), 2) \n",
    "    Entities =   [Experience, Knowledge, Skills, Areas, Diploma, Major]\n",
    "    Relations =   [Experience_skills, Knowledge_skills, Experience_areas, \n",
    "                   Knowledge_areas, Degree_in]\n",
    "\n",
    "    return Entities, Relations, Average_length_sent,  Average_length_word, length_triple_list\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdb8997-ea2a-433a-b388-2936282e25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data,  train_data , dev_data, test_data  = split_to_tran_dev_test(input_path)\n",
    "Entities_1, Relations_1,  Average_length_sent_1,  Average_length_word_1, length_triple_list_1 = transform_format(All_data)\n",
    "Entities_2, Relations_2,  Average_length_sent_2,  Average_length_word_2, length_triple_list_2 = transform_format(train_data)\n",
    "Entities_3, Relations_3,  Average_length_sent_3,  Average_length_word_3, length_triple_list_3 = transform_format(dev_data)\n",
    "Entities_4, Relations_4,  Average_length_sent_4,  Average_length_word_4, length_triple_list_4 = transform_format(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e79203-ed7e-4bd1-bfc8-562fe5a324dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN = [\"Experience\", \"Knowledge\", \"Skills\" , \"Areas\" , \"Diploma\" ,  \"Major\"]\n",
    "RE = [\"Experience_skills\", \"Knowledge_skills\", \"Experience_areas\", \"Knowledge_areas\", \"Degree_in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3e6e365-8d09-423b-b7c8-f1a803a16cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for statistics\n",
    "data = {'All_data':Entities_1+Relations_1 +[str(Average_length_sent_1)] +[str(Average_length_word_1)] +[str(length_triple_list_1)],\n",
    "        'Train':Entities_2+Relations_2+[str(Average_length_sent_2)] +[str(Average_length_word_2)]+[str(length_triple_list_2)], \n",
    "        'Validate':Entities_3+Relations_3+[str(Average_length_sent_3)] +[str(Average_length_word_3)]+[str(length_triple_list_3)],\n",
    "        'Test':Entities_4+Relations_4+[str(Average_length_sent_4)] +[str(Average_length_word_4)]+[str(length_triple_list_4)],\n",
    "       }\n",
    "\n",
    "# Creates pandas DataFrame.\n",
    "df = pd.DataFrame(data, index =EN+RE+['Average_sentence', \"Average_word\", \"Triple\"])\n",
    "# df = df.transpose()\n",
    "df.to_csv('./statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92d88f5-af6b-40de-a58c-960d092ff4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience_skills</th>\n",
       "      <th>Knowledge_skills</th>\n",
       "      <th>Experience_areas</th>\n",
       "      <th>Knowledge_areas</th>\n",
       "      <th>Degree_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>845</td>\n",
       "      <td>1270</td>\n",
       "      <td>101</td>\n",
       "      <td>189</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validate</th>\n",
       "      <td>99</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>110</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Experience_skills Knowledge_skills Experience_areas Knowledge_areas  \\\n",
       "Train                  845             1270              101             189   \n",
       "Validate                99              127               11              19   \n",
       "Test                   110              155               11              34   \n",
       "\n",
       "         Degree_in  \n",
       "Train          122  \n",
       "Validate        14  \n",
       "Test            23  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Train':, 'Experience_skills':'Degree_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b11ed7-6209-4369-916f-7314c920abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define data\n",
    "# train_relation = triple_list(train_path)\n",
    "# val_relation = triple_list(dev_path)\n",
    "# test_relation = triple_list(test_path)\n",
    "# # Create dataframe for statistics\n",
    "# data = {'Train':train_relation, \n",
    "#         'Validate':val_relation,\n",
    "#         'Test':test_relation}\n",
    "\n",
    "# # Creates pandas DataFrame.\n",
    "# df = pd.DataFrame(data, index =RE)\n",
    "# df = df.transpose()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "93697655-a5c4-4782-9d97-6cce956fa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df.columns[[0,1, 2,3,4,5,11,12,13]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78403681-756b-438f-8089-929eb098edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Patterns of Job ; data type: train -  {'Normal': 827, 'SEO': 549}\n",
    "###Triples of train dataset:  {1: 773, 2: 357, 4: 63, 3: 120, 5: 63}\n",
    "###Patterns of Job ; data type: val -  {'Normal': 83, 'SEO': 61}\n",
    "###Triples of val dataset:  {1: 75, 3: 15, 2: 40, 5: 7, 4: 7}\n",
    "###Patterns of Job ; data type: test -  {'Normal': 100, 'SEO': 73}\n",
    "###Triples of test dataset:  {1: 93, 3: 20, 5: 11, 4: 7, 2: 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adbbbd12-9458-4acf-98bd-f23273fe3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\hline\n",
      "          &   SEO &   Normal &   N=1 &   N=2 &   N=3 &   N=4 &   N\\ensuremath{>}=5 \\\\\n",
      "\\hline\n",
      " All\\_data &   683 &     1010 &   941 &   439 &   155 &    77 &     81 \\\\\n",
      " Train    &   549 &      827 &   773 &   357 &   120 &    63 &     63 \\\\\n",
      " Val      &    61 &       83 &    75 &    40 &    15 &     7 &      7 \\\\\n",
      " Test     &    73 &      100 &    93 &    42 &    20 &     7 &     11 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# statistics for overlapping relations\n",
    "data = [{'SEO': 683, 'Normal': 1010,  \"N=1\": 941, \n",
    "        \"N=2\": 439, \"N=3\": 155,  \"N=4\": 77, \"N>=5\": 81},\n",
    "        \n",
    "        {'SEO': 549, 'Normal': 827, \"N=1\": 773, \n",
    "        \"N=2\": 357, \"N=3\": 120,  \"N=4\": 63, \"N>=5\": 63},\n",
    "        \n",
    "        {'SEO': 61, 'Normal': 83, \"N=1\": 75, \n",
    "        \"N=2\": 40, \"N=3\": 15,  \"N=4\": 7, \"N>=5\": 7}, \n",
    "        \n",
    "        {'SEO': 73, 'Normal': 100 , \"N=1\": 93, \n",
    "        \"N=2\": 42, \"N=3\": 20,  \"N=4\": 7, \"N>=5\": 11}]\n",
    "          \n",
    "# Creates DataFrame.\n",
    "df = pd.DataFrame(data, index = ['All_data','Train','Val', \"Test\"] )\n",
    "# df = df.transpose()\n",
    "df.to_csv('./statistics_triple.csv')\n",
    "print(tabulate(df, headers = 'keys', tablefmt = 'latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967b349-245d-4d83-aaec-63bb771ee09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
